{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy import random\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"E:\\EEG DATA\\train_ordered\\02_tcp_le\\meta_final.csv\")\n",
    "data.head()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data['stop_time'] - data['start_time']).idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 231*250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder to load the data from\n",
    "folder = \"E:\\\\EEG DATA\\\\train_ordered\\\\02_tcp_le\\\\train_ready\\\\\"\n",
    "features = []\n",
    "\n",
    "#Making a feature matrix - Links of all CSVs to be loaded\n",
    "for i in range(508):\n",
    "        features.append(folder+str(i)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      1\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     0\n",
       "23     1\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     1\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "478    0\n",
       "479    0\n",
       "480    0\n",
       "481    0\n",
       "482    1\n",
       "483    0\n",
       "484    0\n",
       "485    1\n",
       "486    0\n",
       "487    0\n",
       "488    1\n",
       "489    0\n",
       "490    0\n",
       "491    1\n",
       "492    0\n",
       "493    0\n",
       "494    1\n",
       "495    0\n",
       "496    0\n",
       "497    0\n",
       "498    0\n",
       "499    1\n",
       "500    0\n",
       "501    0\n",
       "502    1\n",
       "503    0\n",
       "504    0\n",
       "505    0\n",
       "506    1\n",
       "507    0\n",
       "Name: label, Length: 508, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bianrizing the labels\n",
    "def binarize(label):\n",
    "    if label == 'seiz':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "data['label'] = data['label'].apply(lambda lab: binarize(lab))\n",
    "\n",
    "data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process(link):\n",
    "    #Read data into a dataframe\n",
    "    data = pd.read_csv(link, header=None)\n",
    "    #Convert dataframe to numpy matrix for padding\n",
    "    data = data.values\n",
    "    #Pad sequences as per maxlen\n",
    "    data = keras.preprocessing.sequence.pad_sequences(data, padding='post', maxlen=maxlen)\n",
    "    return data \n",
    "\n",
    "# #Making a generator \n",
    "# def generator(features, labels):\n",
    "#     while True:\n",
    "#         #Pick a random index\n",
    "#         index= random.choice(len(features),1)\n",
    "#         #Load and preprocess the data for that index\n",
    "#         batch_features = load_and_process(features[index[0]])\n",
    "#         batch_features = np.array(batch_features).reshape((1, 32, maxlen))\n",
    "#         #Get label for index\n",
    "#         batch_labels = labels[index[0]].reshape(1)\n",
    "#         #YEILD TO THE OVERLORDS!\n",
    "#         print(batch_features.shape)\n",
    "#         print(batch_labels.shape)\n",
    "#         yield  (batch_features, batch_labels)\n",
    "        \n",
    "#With batch_size\n",
    "def generator(features, labels, batch_size):\n",
    "    # Create empty arrays to contain batch of features and labels#\n",
    "    batch_features = np.zeros((batch_size, 32, maxlen))\n",
    "    batch_labels = np.zeros((batch_size,1))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # choose random index in features\n",
    "            index= random.choice(len(features),1)\n",
    "            batch_features[i] = load_and_process(features[index[0]])\n",
    "            batch_labels[i] = labels[index[0]]\n",
    "        print(batch_features.shape,\"|\", batch_labels.shape)\n",
    "        yield batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Visualizing what the generator is actually returning\n",
    "# N = generator(features, data['label'])\n",
    "# print(*N, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 100)               23140400  \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 23,140,501\n",
      "Trainable params: 23,140,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100, input_shape=(32, maxlen), recurrent_dropout=0.2))\n",
    "# model.add(keras.layers.Flatten())\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=10, epochs=20)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "(10, 32, 57750) | (10, 1)\n",
      " 1/10 [==>...........................] - ETA: 17:41 - loss: 11.1597 - acc: 0.3000(10, 32, 57750) | (10, 1)\n",
      " 2/10 [=====>........................] - ETA: 16:02 - loss: 11.9568 - acc: 0.2500(10, 32, 57750) | (10, 1)\n",
      " 3/10 [========>.....................] - ETA: 14:28 - loss: 11.1597 - acc: 0.3000(10, 32, 57750) | (10, 1)\n",
      " 4/10 [===========>..................] - ETA: 12:17 - loss: 10.3626 - acc: 0.3500(10, 32, 57750) | (10, 1)\n",
      " 5/10 [==============>...............] - ETA: 11:04 - loss: 10.8408 - acc: 0.3200(10, 32, 57750) | (10, 1)\n",
      " 6/10 [=================>............] - ETA: 10:02 - loss: 11.4254 - acc: 0.2833"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator(features, data['label'].apply(lambda x: int(x)), 10), samples_per_epoch=10, nb_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('E:\\\\EEG DATA\\\\train_ordered\\\\02_tcp_le\\\\model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
