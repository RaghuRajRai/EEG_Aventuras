{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import numpy as np\n",
    "import keras\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import optimizers\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"E:\\EEG DATA\\train_ordered\\02_tcp_le\\Text_data\\text_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>edf_location</th>\n",
       "      <th>label</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...</td>\n",
       "      <td>0</td>\n",
       "      <td>CLINICAL HISTORY 55yearold righthanded woman C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...</td>\n",
       "      <td>1</td>\n",
       "      <td>CLINICAL HISTORY 27yearold woman focal scleros...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...</td>\n",
       "      <td>0</td>\n",
       "      <td>CLINICAL HISTORY 23yearold male history seizur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...</td>\n",
       "      <td>0</td>\n",
       "      <td>CLINICAL HISTORY 56 year old male small lacuna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...</td>\n",
       "      <td>0</td>\n",
       "      <td>CLINICAL HISTORY 56 year old male small lacuna...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       edf_location  label  \\\n",
       "0           0  E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...      0   \n",
       "1           1  E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...      1   \n",
       "2           2  E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...      0   \n",
       "3           3  E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...      0   \n",
       "4           4  E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...      0   \n",
       "\n",
       "                                              report  \n",
       "0  CLINICAL HISTORY 55yearold righthanded woman C...  \n",
       "1  CLINICAL HISTORY 27yearold woman focal scleros...  \n",
       "2  CLINICAL HISTORY 23yearold male history seizur...  \n",
       "3  CLINICAL HISTORY 56 year old male small lacuna...  \n",
       "4  CLINICAL HISTORY 56 year old male small lacuna...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8a2467d8f34f61a6701bdfbc463272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=181), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d09d4f378e245298763159675e88504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=181), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26611929b9d54c8cb1d9ea664d8503ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=181), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a03b65fba2c4c8cb4725e0bed5a135f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=181), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>edf_location</th>\n",
       "      <th>label</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...</td>\n",
       "      <td>0</td>\n",
       "      <td>clinic histori 55yearold righthand woman cn va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...</td>\n",
       "      <td>1</td>\n",
       "      <td>clinic histori 27yearold woman focal sclerosi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...</td>\n",
       "      <td>0</td>\n",
       "      <td>clinic histori 23yearold male histori seizur 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...</td>\n",
       "      <td>0</td>\n",
       "      <td>clinic histori 56 year old male small lacunar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...</td>\n",
       "      <td>0</td>\n",
       "      <td>clinic histori 56 year old male small lacunar ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       edf_location  label  \\\n",
       "0           0  E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...      0   \n",
       "1           1  E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...      1   \n",
       "2           2  E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...      0   \n",
       "3           3  E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...      0   \n",
       "4           4  E:/EEG DATA/train_ordered/02_tcp_le/Formatted/...      0   \n",
       "\n",
       "                                              report  \n",
       "0  clinic histori 55yearold righthand woman cn va...  \n",
       "1  clinic histori 27yearold woman focal sclerosi ...  \n",
       "2  clinic histori 23yearold male histori seizur 2...  \n",
       "3  clinic histori 56 year old male small lacunar ...  \n",
       "4  clinic histori 56 year old male small lacunar ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All the basic pre-processing: Stopword removal, punctuation removal, stemming, lower casing\n",
    "data['report'] = data['report'].progress_apply(lambda s: str(s))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "def text_process(text):\n",
    "    #String punctuation provides all the necessary checks\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "data['report'] = data['report'].progress_apply(lambda txt: str(txt))\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "def punct_remove(text):\n",
    "    text = ''.join(ch for ch in text if ch not in exclude)\n",
    "    return text\n",
    "data['report'] = data['report'].progress_apply(lambda s: punct_remove(s))\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "stemmer = PorterStemmer()\n",
    "def stemming(text):\n",
    "    words = word_tokenize(text)\n",
    "    new_txt = []\n",
    "    for word in words:\n",
    "        new_txt.append(stemmer.stem(word))\n",
    "    txt = ' '.join(new_txt)\n",
    "    return txt\n",
    "data['report'] = data['report'].progress_apply(lambda s: stemming(s))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 3561)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#data['report'] = data['report'].apply(lambda string: [string])\n",
    "#data['report']=[\" \".join(review) for review in data['report'].values]\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer(max_df=0.9)\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(data['report'])\n",
    "# encode document\n",
    "vector = vectorizer.transform(data['report'])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, data['label'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 3561, 32)          113952    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 500)               1066000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               64128     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,244,209\n",
      "Trainable params: 1,244,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "model=Sequential()\n",
    "model.add(Embedding(vector.shape[1], 32, input_length = vector.shape[1]))\n",
    "model.add(LSTM(500))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "144/144 [==============================] - ETA: 4:42 - loss: 0.6934 - acc: 0.333 - ETA: 4:22 - loss: 0.6938 - acc: 0.416 - ETA: 4:06 - loss: 0.6978 - acc: 0.416 - ETA: 3:35 - loss: 0.7029 - acc: 0.375 - ETA: 3:06 - loss: 0.7019 - acc: 0.383 - ETA: 2:38 - loss: 0.7011 - acc: 0.361 - ETA: 2:12 - loss: 0.7000 - acc: 0.381 - ETA: 1:45 - loss: 0.6982 - acc: 0.416 - ETA: 1:18 - loss: 0.6961 - acc: 0.444 - ETA: 52s - loss: 0.6961 - acc: 0.450 - ETA: 26s - loss: 0.6948 - acc: 0.46 - 319s 2s/step - loss: 0.6935 - acc: 0.4722\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - ETA: 4:54 - loss: 0.5907 - acc: 0.750 - ETA: 4:28 - loss: 0.7127 - acc: 0.750 - ETA: 4:04 - loss: 0.6877 - acc: 0.722 - ETA: 3:35 - loss: 0.7025 - acc: 0.645 - ETA: 3:08 - loss: 0.7067 - acc: 0.600 - ETA: 2:43 - loss: 0.7026 - acc: 0.597 - ETA: 2:15 - loss: 0.7053 - acc: 0.559 - ETA: 1:48 - loss: 0.7027 - acc: 0.562 - ETA: 1:21 - loss: 0.7008 - acc: 0.564 - ETA: 54s - loss: 0.6986 - acc: 0.575 - ETA: 27s - loss: 0.6963 - acc: 0.59 - 322s 2s/step - loss: 0.6961 - acc: 0.5833\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - ETA: 4:38 - loss: 0.6807 - acc: 0.666 - ETA: 4:11 - loss: 0.6840 - acc: 0.625 - ETA: 3:56 - loss: 0.6873 - acc: 0.583 - ETA: 3:25 - loss: 0.6924 - acc: 0.520 - ETA: 3:00 - loss: 0.6914 - acc: 0.533 - ETA: 2:33 - loss: 0.6873 - acc: 0.583 - ETA: 2:06 - loss: 0.6872 - acc: 0.583 - ETA: 1:40 - loss: 0.6881 - acc: 0.572 - ETA: 1:15 - loss: 0.6888 - acc: 0.564 - ETA: 49s - loss: 0.6877 - acc: 0.575 - ETA: 24s - loss: 0.6860 - acc: 0.59 - 298s 2s/step - loss: 0.6868 - acc: 0.5833\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - ETA: 4:28 - loss: 0.6853 - acc: 0.583 - ETA: 4:02 - loss: 0.6752 - acc: 0.666 - ETA: 3:38 - loss: 0.6747 - acc: 0.666 - ETA: 3:13 - loss: 0.6799 - acc: 0.625 - ETA: 2:48 - loss: 0.6807 - acc: 0.616 - ETA: 2:23 - loss: 0.6877 - acc: 0.569 - ETA: 1:59 - loss: 0.6889 - acc: 0.559 - ETA: 1:36 - loss: 0.6933 - acc: 0.531 - ETA: 1:12 - loss: 0.6891 - acc: 0.555 - ETA: 49s - loss: 0.6913 - acc: 0.541 - ETA: 24s - loss: 0.6854 - acc: 0.57 - 298s 2s/step - loss: 0.6840 - acc: 0.5833\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - ETA: 4:32 - loss: 0.6512 - acc: 0.750 - ETA: 4:03 - loss: 0.6747 - acc: 0.625 - ETA: 3:39 - loss: 0.6768 - acc: 0.611 - ETA: 3:13 - loss: 0.6730 - acc: 0.625 - ETA: 2:51 - loss: 0.6786 - acc: 0.600 - ETA: 2:29 - loss: 0.6751 - acc: 0.611 - ETA: 2:04 - loss: 0.6860 - acc: 0.571 - ETA: 1:39 - loss: 0.6822 - acc: 0.583 - ETA: 1:15 - loss: 0.6873 - acc: 0.564 - ETA: 50s - loss: 0.6841 - acc: 0.575 - ETA: 25s - loss: 0.6859 - acc: 0.56 - 302s 2s/step - loss: 0.6814 - acc: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23624c56a58>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=12, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - ETA:  - 15s 407ms/step\n",
      "[0.6599593549161344, 0.6486486518705213]\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "181/181 [==============================] - ETA: 5:54 - loss: 0.6932 - acc: 0.500 - ETA: 5:49 - loss: 0.6825 - acc: 0.583 - ETA: 5:14 - loss: 1.0458 - acc: 0.638 - ETA: 4:42 - loss: 0.9558 - acc: 0.687 - ETA: 4:14 - loss: 0.9017 - acc: 0.666 - ETA: 3:47 - loss: 0.8673 - acc: 0.638 - ETA: 3:28 - loss: 0.8412 - acc: 0.631 - ETA: 3:03 - loss: 0.8245 - acc: 0.604 - ETA: 2:38 - loss: 0.8101 - acc: 0.592 - ETA: 2:14 - loss: 0.7963 - acc: 0.608 - ETA: 1:47 - loss: 0.7860 - acc: 0.606 - ETA: 1:21 - loss: 0.7786 - acc: 0.597 - ETA: 54s - loss: 0.7713 - acc: 0.596 - ETA: 28s - loss: 0.7660 - acc: 0.58 - ETA: 2s - loss: 0.7596 - acc: 0.5944 - 401s 2s/step - loss: 0.7586 - acc: 0.5967\n",
      "Epoch 2/7\n",
      "181/181 [==============================] - ETA: 5:42 - loss: 0.6401 - acc: 0.666 - ETA: 5:57 - loss: 0.7580 - acc: 0.500 - ETA: 5:40 - loss: 0.7484 - acc: 0.444 - ETA: 5:14 - loss: 0.7226 - acc: 0.541 - ETA: 4:52 - loss: 0.7077 - acc: 0.583 - ETA: 4:31 - loss: 0.7065 - acc: 0.569 - ETA: 4:04 - loss: 0.7055 - acc: 0.559 - ETA: 3:34 - loss: 0.6958 - acc: 0.593 - ETA: 3:05 - loss: 0.6889 - acc: 0.611 - ETA: 2:36 - loss: 0.6821 - acc: 0.625 - ETA: 2:05 - loss: 0.6785 - acc: 0.628 - ETA: 1:34 - loss: 0.6902 - acc: 0.604 - ETA: 1:03 - loss: 0.6946 - acc: 0.583 - ETA: 33s - loss: 0.6924 - acc: 0.589 - ETA: 2s - loss: 0.6889 - acc: 0.6000 - 465s 3s/step - loss: 0.6898 - acc: 0.5967\n",
      "Epoch 3/7\n",
      "181/181 [==============================] - ETA: 6:10 - loss: 0.7097 - acc: 0.416 - ETA: 5:38 - loss: 0.6851 - acc: 0.583 - ETA: 5:05 - loss: 0.6697 - acc: 0.666 - ETA: 4:40 - loss: 0.6632 - acc: 0.687 - ETA: 4:21 - loss: 0.6620 - acc: 0.683 - ETA: 3:54 - loss: 0.6733 - acc: 0.638 - ETA: 3:28 - loss: 0.6743 - acc: 0.631 - ETA: 3:02 - loss: 0.6827 - acc: 0.593 - ETA: 2:40 - loss: 0.6809 - acc: 0.601 - ETA: 2:15 - loss: 0.6827 - acc: 0.591 - ETA: 1:47 - loss: 0.6795 - acc: 0.606 - ETA: 1:21 - loss: 0.6796 - acc: 0.604 - ETA: 54s - loss: 0.6829 - acc: 0.589 - ETA: 28s - loss: 0.6828 - acc: 0.58 - ETA: 2s - loss: 0.6802 - acc: 0.6000 - 400s 2s/step - loss: 0.6811 - acc: 0.5967\n",
      "Epoch 4/7\n",
      "181/181 [==============================] - ETA: 6:15 - loss: 0.6837 - acc: 0.583 - ETA: 5:39 - loss: 0.6898 - acc: 0.541 - ETA: 5:07 - loss: 0.6797 - acc: 0.611 - ETA: 4:41 - loss: 0.6731 - acc: 0.645 - ETA: 4:16 - loss: 0.6818 - acc: 0.600 - ETA: 3:50 - loss: 0.6868 - acc: 0.569 - ETA: 3:24 - loss: 0.6863 - acc: 0.571 - ETA: 2:59 - loss: 0.6859 - acc: 0.572 - ETA: 2:33 - loss: 0.6887 - acc: 0.555 - ETA: 2:07 - loss: 0.6870 - acc: 0.566 - ETA: 1:41 - loss: 0.6853 - acc: 0.575 - ETA: 1:16 - loss: 0.6850 - acc: 0.576 - ETA: 51s - loss: 0.6847 - acc: 0.576 - ETA: 26s - loss: 0.6831 - acc: 0.58 - ETA: 2s - loss: 0.6801 - acc: 0.5944 - 375s 2s/step - loss: 0.6792 - acc: 0.5967\n",
      "Epoch 5/7\n",
      "181/181 [==============================] - ETA: 5:29 - loss: 0.4986 - acc: 0.833 - ETA: 5:23 - loss: 0.5617 - acc: 0.791 - ETA: 4:54 - loss: 0.6276 - acc: 0.666 - ETA: 4:23 - loss: 0.6341 - acc: 0.666 - ETA: 3:56 - loss: 0.6490 - acc: 0.633 - ETA: 3:31 - loss: 0.6455 - acc: 0.652 - ETA: 3:07 - loss: 0.6457 - acc: 0.654 - ETA: 2:45 - loss: 0.6546 - acc: 0.635 - ETA: 2:22 - loss: 0.6674 - acc: 0.601 - ETA: 2:00 - loss: 0.6686 - acc: 0.600 - ETA: 1:35 - loss: 0.6697 - acc: 0.598 - ETA: 1:11 - loss: 0.6705 - acc: 0.597 - ETA: 48s - loss: 0.6712 - acc: 0.596 - ETA: 24s - loss: 0.6718 - acc: 0.59 - ETA: 1s - loss: 0.6723 - acc: 0.5944 - 348s 2s/step - loss: 0.6717 - acc: 0.5967\n",
      "Epoch 6/7\n",
      "181/181 [==============================] - ETA: 5:05 - loss: 0.6407 - acc: 0.666 - ETA: 4:40 - loss: 0.7347 - acc: 0.500 - ETA: 4:17 - loss: 0.7248 - acc: 0.500 - ETA: 3:55 - loss: 0.7016 - acc: 0.562 - ETA: 3:34 - loss: 0.6798 - acc: 0.616 - ETA: 3:12 - loss: 0.6734 - acc: 0.625 - ETA: 2:51 - loss: 0.6686 - acc: 0.631 - ETA: 2:29 - loss: 0.6646 - acc: 0.635 - ETA: 2:08 - loss: 0.6746 - acc: 0.620 - ETA: 1:47 - loss: 0.6721 - acc: 0.625 - ETA: 1:26 - loss: 0.6788 - acc: 0.606 - ETA: 1:05 - loss: 0.6747 - acc: 0.618 - ETA: 44s - loss: 0.6774 - acc: 0.609 - ETA: 22s - loss: 0.6776 - acc: 0.60 - ETA: 1s - loss: 0.6814 - acc: 0.5944 - 323s 2s/step - loss: 0.6807 - acc: 0.5967\n",
      "Epoch 7/7\n",
      "181/181 [==============================] - ETA: 4:57 - loss: 0.5807 - acc: 0.833 - ETA: 4:36 - loss: 0.6101 - acc: 0.750 - ETA: 4:16 - loss: 0.6675 - acc: 0.638 - ETA: 3:54 - loss: 0.6552 - acc: 0.666 - ETA: 3:33 - loss: 0.6311 - acc: 0.716 - ETA: 3:12 - loss: 0.6412 - acc: 0.694 - ETA: 2:50 - loss: 0.6595 - acc: 0.654 - ETA: 2:29 - loss: 0.6689 - acc: 0.625 - ETA: 2:08 - loss: 0.6704 - acc: 0.620 - ETA: 1:48 - loss: 0.6649 - acc: 0.641 - ETA: 1:30 - loss: 0.6695 - acc: 0.628 - ETA: 1:08 - loss: 0.6728 - acc: 0.618 - ETA: 46s - loss: 0.6733 - acc: 0.615 - ETA: 24s - loss: 0.6793 - acc: 0.59 - ETA: 1s - loss: 0.6794 - acc: 0.5944 - 343s 2s/step - loss: 0.6789 - acc: 0.5967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x236270dbeb8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we let the model train on the entire data for better classification. \n",
    "#Re-compile the model first or the training is applied additionally to the current model.\n",
    "model.fit(vector, data['label'], epochs = 7, batch_size = 12, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "#Save the weights and architecture of the model\n",
    "model.save('E:/EEG Analysis/CLASSIFIER/text_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "txt = punct_remove(txt)\n",
    "print(txt)\n",
    "txt  = stemming(txt)\n",
    "print(txt)\n",
    "vector = vectorizer.transform([txt])\n",
    "res = model.predict(vector)\n",
    "print(res)\n",
    "print(model.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
